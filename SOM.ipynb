{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19c82273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.fftpack import dct\n",
    "import csv\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "# from minisom import MiniSom ## Minisom library and module is used for performing Self Organizing Maps\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "np.set_printoptions(suppress=True) #Force-suppress all exponential notation\n",
    "# import simpsom as sps\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn_som.som import SOM   #***\n",
    "from sklearn import datasets  \n",
    "from sklearn.preprocessing import normalize\n",
    "import seaborn as sns\n",
    "# from kneed import KneeLocator, DataGenerator as dg \n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "# import tensorflow as tf\n",
    "from collections import Counter \n",
    "import time \n",
    "from numba import jit \n",
    "import datetime as dt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6ba69e",
   "metadata": {},
   "source": [
    "#### LAB channel ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a15a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275\n"
     ]
    }
   ],
   "source": [
    "path = './All_Images/'\n",
    "all_images = os.listdir(path)\n",
    "length = len(all_images)\n",
    "\n",
    "print(length)\n",
    "windowsize_r = 64\n",
    "windowsize_c = 64\n",
    "dim = (384,512)\n",
    "\n",
    "names = []\n",
    "\n",
    "n_blocks = int(dim[0]/windowsize_r * dim[1]/windowsize_c)   \n",
    "data = np.zeros((n_blocks*length,windowsize_r)) \n",
    "\n",
    "counter_n = -1\n",
    "for i in range(length):\n",
    "   \n",
    "    image_path = os.path.join(path, all_images[i])\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "#     try:\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     except:\n",
    "#         img = img\n",
    "\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)    \n",
    "    l_channel,a_channel,b_channel = cv2.split(img)\n",
    "    \n",
    " #   img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)    \n",
    "\n",
    "    counter_row = -1\n",
    "    counter_col = -1\n",
    "    \n",
    "    for r in range(0,l_channel.shape[0] , windowsize_r):\n",
    "        counter_row += 1\n",
    "        counter_col = -1\n",
    "        for c in range(0,l_channel.shape[1] , windowsize_c):\n",
    "            \n",
    "            counter_n += 1\n",
    "            counter_col += 1\n",
    "            window = l_channel[r:r+windowsize_r,c:c+windowsize_c]\n",
    "#             data[counter_n,0] = calcEntropy2dSpeedUp(window) \n",
    "            img_dct = abs(dct( dct( window, axis=0, norm='ortho' ), axis=1, norm='ortho' ))\n",
    "\n",
    "            for j in range(windowsize_r):\n",
    "                soton =  np.sum(img_dct[0:j+1,j])\n",
    "                satr = np.sum(img_dct[j,0:j])\n",
    "                summation = satr + soton\n",
    "#                 summation=np.log(summation)\n",
    "                \n",
    "                data[counter_n,j] = round(summation,2)                \n",
    "            image_name  = all_images[i].split()  \n",
    "\n",
    "            names.append(image_name)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62feaf7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8293.92, 2584.17, 1387.97, ...,  536.05,  528.17,  489.9 ],\n",
       "       [8722.47, 2515.61, 1392.91, ...,  640.55,  551.6 ,  653.83],\n",
       "       [8317.58,  954.84, 2376.17, ...,  545.83,  558.3 ,  601.08],\n",
       "       ...,\n",
       "       [7142.44, 1028.73,  410.39, ...,   17.47,   14.81,   18.51],\n",
       "       [4569.5 ,  668.06,  286.02, ...,   27.97,   20.3 ,   40.24],\n",
       "       [1158.23,  872.47,  184.58, ...,   11.73,   10.09,    7.61]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97a2f84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list_matrix = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c15e725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13200, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_list_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66bf6475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8293.92, 2584.17, 1387.97, ...,  536.05,  528.17,  489.9 ],\n",
       "       [8722.47, 2515.61, 1392.91, ...,  640.55,  551.6 ,  653.83],\n",
       "       [8317.58,  954.84, 2376.17, ...,  545.83,  558.3 ,  601.08],\n",
       "       ...,\n",
       "       [7142.44, 1028.73,  410.39, ...,   17.47,   14.81,   18.51],\n",
       "       [4569.5 ,  668.06,  286.02, ...,   27.97,   20.3 ,   40.24],\n",
       "       [1158.23,  872.47,  184.58, ...,   11.73,   10.09,    7.61]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_list_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2fc2daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98dafe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_with_name = np.concatenate((names,final_list_matrix),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6988bf41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['I01.BMP', '8293.92', '2584.17', ..., '536.05', '528.17',\n",
       "        '489.9'],\n",
       "       ['I01.BMP', '8722.47', '2515.61', ..., '640.55', '551.6',\n",
       "        '653.83'],\n",
       "       ['I01.BMP', '8317.58', '954.84', ..., '545.83', '558.3', '601.08'],\n",
       "       ...,\n",
       "       ['i25_08_5.bmp', '7142.44', '1028.73', ..., '17.47', '14.81',\n",
       "        '18.51'],\n",
       "       ['i25_08_5.bmp', '4569.5', '668.06', ..., '27.97', '20.3',\n",
       "        '40.24'],\n",
       "       ['i25_08_5.bmp', '1158.23', '872.47', ..., '11.73', '10.09',\n",
       "        '7.61']], dtype='<U32')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_with_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e915345c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13200, 65)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_with_name.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ce17b3",
   "metadata": {},
   "source": [
    "#### library ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa23be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script to implement simple self organizing map using PyTorch, with methods\n",
    "similar to clustering method in sklearn.\n",
    "\n",
    "@author: Riley Smith\n",
    "Created: 1-27-21\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class new_som():\n",
    "    \"\"\"\n",
    "    The 2-D, rectangular grid self-organizing map class using Numpy.\n",
    "    \"\"\"\n",
    "    def __init__(self, m=3, n=3, dim=3, lr=0.01, sigma=0.5, max_iter=50000,\n",
    "                    random_state=42):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        m : int, default=3\n",
    "            The shape along dimension 0 (vertical) of the SOM.\n",
    "        n : int, default=3\n",
    "            The shape along dimesnion 1 (horizontal) of the SOM.\n",
    "        dim : int, default=3\n",
    "            The dimensionality (number of features) of the input space.\n",
    "        lr : float, default=1\n",
    "            The initial step size for updating the SOM weights.\n",
    "        sigma : float, optional\n",
    "            Optional parameter for magnitude of change to each weight. Does not\n",
    "            update over training (as does learning rate). Higher values mean\n",
    "            more aggressive updates to weights.\n",
    "        max_iter : int, optional\n",
    "            Optional parameter to stop training if you reach this many\n",
    "            interation.\n",
    "        random_state : int, optional\n",
    "            Optional integer seed to the random number generator for weight\n",
    "            initialization. This will be used to create a new instance of Numpy's\n",
    "            default random number generator (it will not call np.random.seed()).\n",
    "            Specify an integer for deterministic results.\n",
    "        \"\"\"\n",
    "        # Initialize descriptive features of SOM\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.dim = dim\n",
    "        self.shape = (m, n)\n",
    "        self.initial_lr = lr\n",
    "        self.lr = lr\n",
    "        self.sigma = sigma\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "        # Initialize weights\n",
    "        self.random_state = random_state\n",
    "        rng = np.random.default_rng(random_state)\n",
    "        self.weights = rng.normal(size=(m * n, dim))\n",
    "        self._locations = self._get_locations(m, n)\n",
    "\n",
    "        # Set after fitting\n",
    "        self._inertia = None\n",
    "        self._n_iter_ = None\n",
    "        self._trained = False\n",
    "\n",
    "    def _get_locations(self, m, n):\n",
    "        \"\"\"\n",
    "        Return the indices of an m by n array.\n",
    "        \"\"\"\n",
    "        return np.argwhere(np.ones(shape=(m, n))).astype(np.int64)\n",
    "\n",
    "    def _find_bmu(self, x):\n",
    "        \"\"\"\n",
    "        Find the index of the best matching unit for the input vector x.\n",
    "        \"\"\"\n",
    "        # Stack x to have one row per weight\n",
    "        x_stack = np.stack([x]*(self.m*self.n), axis=0)\n",
    "        ## Calculate distance between x and each weight\n",
    "        distance = np.linalg.norm(x_stack - self.weights, axis=1)\n",
    "        # Find index of best matching unit\n",
    "        return np.argmin(distance)\n",
    "\n",
    "    def step(self, x):\n",
    "        \"\"\"\n",
    "        Do one step of training on the given input vector.\n",
    "        \"\"\"\n",
    "        # Stack x to have one row per weight\n",
    "        x_stack = np.stack([x]*(self.m*self.n), axis=0)\n",
    "\n",
    "        # Get index of best matching unit\n",
    "        bmu_index = self._find_bmu(x)\n",
    "\n",
    "        # Find location of best matching unit\n",
    "        bmu_location = self._locations[bmu_index,:]\n",
    "\n",
    "        # Find square distance from each weight to the BMU\n",
    "        stacked_bmu = np.stack([bmu_location]*(self.m*self.n), axis=0)\n",
    "        bmu_distance = np.sum(np.power(self._locations.astype(np.float64) - stacked_bmu.astype(np.float64), 2), axis=1)\n",
    "\n",
    "        ## Compute update neighborhood\n",
    "        neighborhood = np.exp((bmu_distance / (self.sigma ** 2)) * -1)\n",
    "        local_step = self.lr * neighborhood\n",
    "\n",
    "        # Stack local step to be proper shape for update\n",
    "        local_multiplier = np.stack([local_step]*(self.dim), axis=1)\n",
    "\n",
    "        # Multiply by difference between input and weights\n",
    "        delta = local_multiplier * (x_stack - self.weights)\n",
    "\n",
    "        ## Update weights\n",
    "        self.weights += delta\n",
    "\n",
    "    def _compute_point_intertia(self, x):\n",
    "        \"\"\"\n",
    "        Compute the inertia of a single point. Inertia defined as squared distance\n",
    "        from point to closest cluster center (BMU)\n",
    "        \"\"\"\n",
    "        # Find BMU\n",
    "        bmu_index = self._find_bmu(x)\n",
    "        bmu = self.weights[bmu_index]\n",
    "        # Compute sum of squared distance (just euclidean distance) from x to bmu\n",
    "        return np.sum(np.square(x - bmu))\n",
    "\n",
    "    def fit(self, X, epochs=150, shuffle=False): ################################## number of epochs\n",
    "        \"\"\"\n",
    "        Take data (a tensor of type float64) as input and fit the SOM to that\n",
    "        data for the specified number of epochs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray\n",
    "            Training data. Must have shape (n, self.dim) where n is the number\n",
    "            of training samples.\n",
    "        epochs : int, default=1\n",
    "            The number of times to loop through the training data when fitting.\n",
    "        shuffle : bool, default True\n",
    "            Whether or not to randomize the order of train data when fitting.\n",
    "            Can be seeded with np.random.seed() prior to calling fit.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "            Fits the SOM to the given data but does not return anything.\n",
    "        \"\"\"\n",
    "        # Count total number of iterations\n",
    "        global_iter_counter = 0\n",
    "        n_samples = X.shape[0]\n",
    "        total_iterations = np.minimum(epochs * n_samples, self.max_iter)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Break if past max number of iterations\n",
    "            if global_iter_counter > self.max_iter:\n",
    "                break\n",
    "\n",
    "            if shuffle:\n",
    "                rng = np.random.default_rng(self.random_state)\n",
    "                indices = rng.permutation(n_samples)\n",
    "            else:\n",
    "                indices = np.arange(n_samples)\n",
    "\n",
    "            # Train\n",
    "            for idx in indices:\n",
    "                # Break if past max number of iterations\n",
    "                if global_iter_counter > self.max_iter:\n",
    "                    break\n",
    "                input = X[idx]\n",
    "                # Do one step of training\n",
    "                self.step(input)\n",
    "                ## Update learning rate\n",
    "                global_iter_counter += 1\n",
    "                self.lr = (1 - (global_iter_counter / total_iterations)) * self.initial_lr\n",
    "\n",
    "        # Compute inertia\n",
    "        inertia = np.sum(np.array([float(self._compute_point_intertia(x)) for x in X]))\n",
    "        self._inertia_ = inertia\n",
    "\n",
    "        # Set n_iter_ attribute\n",
    "        self._n_iter_ = global_iter_counter\n",
    "\n",
    "        # Set trained flag\n",
    "        self._trained = True\n",
    "\n",
    "        return\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict cluster for each element in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray\n",
    "            An ndarray of shape (n, self.dim) where n is the number of samples.\n",
    "            The data to predict clusters for.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        labels : ndarray\n",
    "            An ndarray of shape (n,). The predicted cluster index for each item\n",
    "            in X.\n",
    "        \"\"\"\n",
    "        # Check to make sure SOM has been fit\n",
    "        if not self._trained:\n",
    "            raise NotImplementedError('SOM object has no predict() method until after calling fit().')\n",
    "\n",
    "        # Make sure X has proper shape\n",
    "        assert len(X.shape) == 2, f'X should have two dimensions, not {len(X.shape)}'\n",
    "        assert X.shape[1] == self.dim, f'This SOM has dimesnion {self.dim}. Received input with dimension {X.shape[1]}'\n",
    "\n",
    "        labels = np.array([self._find_bmu(x) for x in X])\n",
    "        return labels\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transform the data X into cluster distance space.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray\n",
    "            Data of shape (n, self.dim) where n is the number of samples. The\n",
    "            data to transform.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        transformed : ndarray\n",
    "            Transformed data of shape (n, self.n*self.m). The Euclidean distance\n",
    "            from each item in X to each cluster center.\n",
    "        \"\"\"\n",
    "        # Stack data and cluster centers\n",
    "        X_stack = np.stack([X]*(self.m*self.n), axis=1)\n",
    "        cluster_stack = np.stack([self.weights]*X.shape[0], axis=0)\n",
    "\n",
    "        # Compute difference\n",
    "        diff = X_stack - cluster_stack\n",
    "\n",
    "        # Take and return norm\n",
    "        return np.linalg.norm(diff, axis=2)\n",
    "\n",
    "    def fit_predict(self, X, **kwargs):\n",
    "        \"\"\"\n",
    "        Convenience method for calling fit(X) followed by predict(X).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray\n",
    "            Data of shape (n, self.dim). The data to fit and then predict.\n",
    "        **kwargs\n",
    "            Optional keyword arguments for the .fit() method.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        labels : ndarray\n",
    "            ndarray of shape (n,). The index of the predicted cluster for each\n",
    "            item in X (after fitting the SOM to the data in X).\n",
    "        \"\"\"\n",
    "        # Fit to data\n",
    "        self.fit(X, **kwargs)\n",
    "\n",
    "        # Return predictions\n",
    "        return self.predict(X)\n",
    "\n",
    "    def fit_transform(self, X, **kwargs):\n",
    "        \"\"\"\n",
    "        Convenience method for calling fit(X) followed by transform(X). Unlike\n",
    "        in sklearn, this is not implemented more efficiently (the efficiency is\n",
    "        the same as calling fit(X) directly followed by transform(X)).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray\n",
    "            Data of shape (n, self.dim) where n is the number of samples.\n",
    "        **kwargs\n",
    "            Optional keyword arguments for the .fit() method.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        transformed : ndarray\n",
    "            ndarray of shape (n, self.m*self.n). The Euclidean distance\n",
    "            from each item in X to each cluster center.\n",
    "        \"\"\"\n",
    "        # Fit to data\n",
    "        self.fit(X, **kwargs)\n",
    "\n",
    "        # Return points in cluster distance space\n",
    "        return self.transform(X)\n",
    "\n",
    "    @property\n",
    "    def cluster_centers_(self):\n",
    "        return self.weights.reshape(self.m, self.n, self.dim)\n",
    "\n",
    "    @property\n",
    "    def inertia_(self):\n",
    "        if self._inertia_ is None:\n",
    "            raise AttributeError('SOM does not have inertia until after calling fit()')\n",
    "        return self._inertia_\n",
    "\n",
    "    @property\n",
    "    def n_iter_(self):\n",
    "        if self._n_iter_ is None:\n",
    "            raise AttributeError('SOM does not have n_iter_ attribute until after calling fit()')\n",
    "        return self._n_iter_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ce777e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = new_som()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c627e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_som = new_som(m=1, n=3, dim=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "200446f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_som.fit(final_with_name[:,53:65].astype('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a58ab14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_predictions = change_som.predict(final_with_name[:,53:65].astype('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "301b94b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7dead1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   43,   307,   310, ..., 13197, 13198, 13199]),)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(change_predictions == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09f52b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterr_zero = np.asarray(np.where(change_predictions == 0))  ### tuple to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1de0aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   43,   307,   310, ..., 13197, 13198, 13199]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterr_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d46592f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6461"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterr_zero.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f33fdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     1,     2, ..., 13044, 13045, 13046]),)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(change_predictions == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81949fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterr_one = np.asarray(np.where(change_predictions == 1))  ### tuple to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f76585f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     1,     2, ..., 13044, 13045, 13046]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterr_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60f48961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4115"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterr_one.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00eb9539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    3,     4,     5, ..., 13025, 13039, 13040]),)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(change_predictions == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27c08b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterr_two = np.asarray(np.where(change_predictions == 2))  ### tuple to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63ea0b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    3,     4,     5, ..., 13025, 13039, 13040]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterr_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f04578e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2624"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterr_two.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23249130",
   "metadata": {},
   "source": [
    "#### Cluster zero ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "268c906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterr_zero_final = final_with_name[clusterr_zero,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "371a0347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['I01.BMP', '6135.83', '1799.4', ..., '270.81', '317.82',\n",
       "         '233.58'],\n",
       "        ['i01_08_1.bmp', '6391.06', '2227.16', ..., '212.27', '172.45',\n",
       "         '219.04'],\n",
       "        ['i01_08_1.bmp', '6376.11', '1318.65', ..., '132.05', '179.7',\n",
       "         '271.26'],\n",
       "        ...,\n",
       "        ['i25_08_5.bmp', '7142.44', '1028.73', ..., '17.47', '14.81',\n",
       "         '18.51'],\n",
       "        ['i25_08_5.bmp', '4569.5', '668.06', ..., '27.97', '20.3',\n",
       "         '40.24'],\n",
       "        ['i25_08_5.bmp', '1158.23', '872.47', ..., '11.73', '10.09',\n",
       "         '7.61']]], dtype='<U32')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterr_zero_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ad66d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterr_zero_final = np.squeeze(clusterr_zero_final, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3df92c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6461, 65)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterr_zero_final.shape          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "344d8d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6461"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusterr_zero_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0709719d",
   "metadata": {},
   "source": [
    "#### Cluster one ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be00d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterr_one_final = final_with_name[clusterr_one,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7836901f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['I01.BMP', '8293.92', '2584.17', ..., '536.05', '528.17',\n",
       "         '489.9'],\n",
       "        ['I01.BMP', '8722.47', '2515.61', ..., '640.55', '551.6',\n",
       "         '653.83'],\n",
       "        ['I01.BMP', '8317.58', '954.84', ..., '545.83', '558.3',\n",
       "         '601.08'],\n",
       "        ...,\n",
       "        ['i25_08_2.bmp', '12742.98', '6019.24', ..., '320.43', '190.56',\n",
       "         '161.81'],\n",
       "        ['i25_08_2.bmp', '7979.17', '7255.15', ..., '284.7', '254.56',\n",
       "         '264.75'],\n",
       "        ['i25_08_2.bmp', '8815.08', '1854.5', ..., '371.12', '578.2',\n",
       "         '1271.35']]], dtype='<U32')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterr_one_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1721a6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['I01.BMP', '8293.92', '2584.17', '1387.97', '1478.87', '1292.96',\n",
       "        '1027.2', '1071.01', '1090.34', '1264.94', '925.57', '807.05',\n",
       "        '1034.88', '981.67', '860.14', '979.82', '745.81', '710.52',\n",
       "        '849.65', '844.0', '976.61', '1005.06', '1058.58', '913.91',\n",
       "        '994.67', '1049.86', '1160.61', '914.73', '1254.44', '744.78',\n",
       "        '953.28', '882.99', '701.43', '998.52', '758.93', '812.77',\n",
       "        '669.76', '713.79', '698.81', '558.4', '675.43', '599.37',\n",
       "        '603.85', '534.93', '480.05', '466.35', '422.87', '447.53',\n",
       "        '488.16', '305.64', '460.49', '399.14', '443.3', '470.65',\n",
       "        '452.28', '465.17', '435.04', '504.79', '478.86', '576.91',\n",
       "        '515.27', '477.98', '536.05', '528.17', '489.9']], dtype='<U32')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterr_one_final[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ebfa5235",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterr_one_final = np.squeeze(clusterr_one_final, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c85c99c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4115, 65)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterr_one_final.shape          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7416aa",
   "metadata": {},
   "source": [
    "#### Cluster two ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "841e88c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterr_two_final = final_with_name[clusterr_two,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e1ac4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['I01.BMP', '8093.84', '1961.58', ..., '916.73', '573.47',\n",
       "         '618.16'],\n",
       "        ['I01.BMP', '6949.53', '2011.85', ..., '870.75', '699.0',\n",
       "         '865.59'],\n",
       "        ['I01.BMP', '9216.8', '454.58', ..., '725.31', '638.3',\n",
       "         '685.34'],\n",
       "        ...,\n",
       "        ['i25_08_2.bmp', '7207.86', '774.48', ..., '690.71', '553.49',\n",
       "         '598.82'],\n",
       "        ['i25_08_2.bmp', '7132.67', '6275.03', ..., '599.46', '494.71',\n",
       "         '529.74'],\n",
       "        ['i25_08_2.bmp', '7983.34', '1417.09', ..., '460.75', '601.67',\n",
       "         '1296.99']]], dtype='<U32')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterr_two_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b1cd9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterr_two_final = np.squeeze(clusterr_two_final, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7063555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2624, 65)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterr_two_final.shape          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b98464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
